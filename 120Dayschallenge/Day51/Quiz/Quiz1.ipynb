{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. What is the goal of linear SVM classification?**\n",
    "\n",
    "- To find the hyperplane that maximizes the margin between two classes\n",
    "- To minimize the distance between two classes\n",
    "- To find the hyperplane that minimizes the margin between two classes\n",
    "- To find the hyperplane that separates two classes with the minimum number of errors\n",
    "\n",
    "**Answer:** To find the hyperplane that maximizes the margin between two classes.\n",
    "\n",
    "**Explanation:** The goal of linear SVM classification is to find the hyperplane that maximizes the margin between two classes. The margin is the distance between the hyperplane and the closest data points from each class. The larger the margin, the better the separation between the classes.\n",
    "\n",
    "---\n",
    "\n",
    "**2. Which of the following is NOT a parameter of linear SVM classification?**\n",
    "\n",
    "- C\n",
    "- gamma\n",
    "- kernel\n",
    "- tol\n",
    "\n",
    "**Answer:** Kernel\n",
    "\n",
    "**Explanation:** Kernel is a parameter of SVM classification, but it is not specific to linear SVM classification. It is used in non-linear SVM classification to transform the input data into a higher-dimensional space where a hyperplane can be used to separate the classes. C is the penalty parameter of the error term, gamma is a parameter of the RBF kernel, and tol is the tolerance for stopping criterion.\n",
    "\n",
    "---\n",
    "\n",
    "**3. What is the purpose of the kernel trick in SVM?**\n",
    "\n",
    "- To transform the data into a higher-dimensional space where it is easier to separate the classes\n",
    "- To preprocess the data before training the SVM\n",
    "- To visualize the data in a lower-dimensional space\n",
    "- To cluster the data into groups\n",
    "\n",
    "**Answer:** To transform the data into a higher-dimensional space where it is easier to separate the classes.\n",
    "\n",
    "**Explanation:** The kernel trick is used to transform the data into a higher-dimensional space where it is easier to separate the classes using a hyperplane. This is done by computing the dot product between the transformed data points, which is equivalent to applying a nonlinear function to the data.\n",
    "\n",
    "---\n",
    "\n",
    "**4. What is the margin in SVM?**\n",
    "\n",
    "- The distance between the decision boundary and the closest data point from each class\n",
    "- The distance between the decision boundary and the farthest data point from each class\n",
    "- The sum of the distances between the decision boundary and all the data points\n",
    "- The area between the decision boundary and the data points\n",
    "\n",
    "**Answer:** The distance between the decision boundary and the closest data point from each class.\n",
    "\n",
    "**Explanation:** The margin is the distance between the decision boundary and the closest data point from each class. In linear SVM, the goal is to find the decision boundary that maximizes the margin, as this results in better generalization performance.\n",
    "\n",
    "---\n",
    "\n",
    "**5. What is the support vector in SVM?**\n",
    "\n",
    "- A data point that lies on the decision boundary\n",
    "- A data point that is misclassified by the model\n",
    "- A data point that has the highest value of the slack variable\n",
    "- A data point that has the largest margin from the decision boundary\n",
    "\n",
    "**Answer:** A data point that has the largest margin from the decision boundary.\n",
    "\n",
    "**Explanation:** A support vector in SVM is a data point that has the largest margin from the decision boundary. These are the points that are closest to the decision boundary and have the most influence on the position of the boundary.\n",
    "\n",
    "---\n",
    "\n",
    "**6. What is the difference between hard margin and soft margin SVM?**\n",
    "\n",
    "- Hard margin SVM does not allow for misclassification, while soft margin SVM allows for some misclassification\n",
    "- Hard margin SVM uses a linear kernel, while soft margin SVM uses a non-linear kernel\n",
    "- Hard margin SVM has a smaller margin than soft margin SVM\n",
    "- Hard margin SVM is used for non-linearly separable data, while soft margin SVM is used for linearly separable data\n",
    "\n",
    "**Answer:** Hard margin SVM does not allow for misclassification, while soft margin SVM allows for some misclassification.\n",
    "\n",
    "**Explanation:** The main difference between hard margin and soft margin SVM is that hard margin SVM does not allow for any misclassification, while soft margin SVM allows for some misclassification of the data points. This is done to increase the generalization performance of the model, especially when the data is not perfectly separable.\n",
    "\n",
    "---\n",
    "\n",
    "**7. What is the main idea behind using a kernel function in nonlinear SVM classification?**\n",
    "\n",
    "- To transform the data into a higher-dimensional space where it is easier to separate the classes\n",
    "- To reduce the dimensionality of the data before training the SVM\n",
    "- To increase the margin between the classes\n",
    "- To force the model to classify all the data points correctly\n",
    "\n",
    "**Answer:** To transform the data into a higher-dimensional space where it is easier to separate the classes.\n",
    "\n",
    "**Explanation:** The main idea behind using a kernel function in nonlinear SVM classification is to transform the data into a higher-dimensional space where it is easier to separate the classes using a hyperplane. This is done by computing the dot product between the transformed data points, which is equivalent to applying a nonlinear function to the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

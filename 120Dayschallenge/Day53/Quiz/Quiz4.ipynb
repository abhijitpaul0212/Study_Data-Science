{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. What is the purpose of bagging in Random Forest Classifier?**\n",
    "\n",
    "- To combine predictions from multiple classifiers\n",
    "- To randomly sample features for each tree\n",
    "- To optimize hyperparameters\n",
    "- To prune unnecessary branches from decision trees\n",
    "\n",
    "**Answer:** To combine predictions from multiple classifiers\n",
    "\n",
    "**Explanation:** Bagging (Bootstrap Aggregating) is a technique used in Random Forest Classifier where multiple decision trees are trained on randomly sampled subsets of features and data samples with replacement. This helps in reducing the correlation between trees and improves the diversity and accuracy of the ensemble.\n",
    "\n",
    "---\n",
    "\n",
    "**2. What is the maximum number of decision trees in a Random Forest Classifier?**\n",
    "\n",
    "- Equal to the number of data samples\n",
    "- Equal to the number of features\n",
    "- Equal to the number of classes in the target variable\n",
    "- A predefined hyperparameter\n",
    "\n",
    "**Answer:** A predefined hyperparameter\n",
    "\n",
    "**Explanation:** The maximum number of decision trees in a Random Forest Classifier is a hyperparameter that needs to be predefined before training the model. It determines the number of trees in the ensemble and can be set based on the problem's complexity and computational resources available.\n",
    "\n",
    "---\n",
    "\n",
    "**3. What is the purpose of feature importance in Random Forest Classifier?**\n",
    "\n",
    "- To measure the accuracy of the model\n",
    "- To determine the optimal number of trees\n",
    "- To rank the importance of different features\n",
    "- To control overfitting in the model\n",
    "\n",
    "**Answer:** To rank the importance of different features\n",
    "\n",
    "**Explanation:** Feature importance in Random Forest Classifier is a measure that ranks the importance of different features used in the model. It helps in identifying which features contribute the most towards making accurate predictions and can be useful for feature selection and model interpretation.\n",
    "\n",
    "---\n",
    "\n",
    "**4. How does Random Forest Classifier handle missing values?**\n",
    "\n",
    "- By deleting rows with missing values\n",
    "- By imputing missing values with mean/median/mode\n",
    "- By using surrogate splits\n",
    "- By ignoring missing values during tree construction\n",
    "\n",
    "**Answer:** By using surrogate splits\n",
    "\n",
    "**Explanation:** Random Forest Classifier handles missing values by using surrogate splits. Surrogate splits are additional splits that are used in decision trees when a feature has a missing value for a data sample. These surrogate splits help in determining the best path for the sample down the tree, even if the original feature has a missing value.\n",
    "\n",
    "---\n",
    "\n",
    "**5. What is the main advantage of using a Random Forest Classifier over a single decision tree?**\n",
    "\n",
    "- Faster training time\n",
    "- Higher accuracy\n",
    "- Lower complexity\n",
    "- Simpler model interpretation\n",
    "\n",
    "**Answer:** Higher accuracy\n",
    "\n",
    "**Explanation:** The main advantage of using a Random Forest Classifier over a single decision tree is that it typically leads to higher accuracy. By combining predictions from multiple trees, Random Forest can reduce overfitting and provide more robust predictions.\n",
    "\n",
    "---\n",
    "\n",
    "**6. What is the purpose of out-of-bag (OOB) samples in Random Forest Classifier?**\n",
    "\n",
    "- To validate the model during training\n",
    "- To test the model after training\n",
    "- To prune unnecessary branches from decision trees\n",
    "- To improve the accuracy of the model\n",
    "\n",
    "**Answer:** To validate the model during training\n",
    "\n",
    "**Explanation:** Out-of-bag (OOB) samples in Random Forest Classifier are the data samples that are not included in the bootstrap sample used to train each tree. These samples can be used to validate the model during training without the need for a separate validation set, providing an estimate of the model's performance without the need for additional data.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

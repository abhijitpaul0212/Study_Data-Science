{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. What is the main goal of Boosting Technique in machine learning?**\n",
    "\n",
    "- To reduce the number of features in the dataset\n",
    "- To reduce the training time of the model\n",
    "- To improve the accuracy of the model\n",
    "- To increase the interpretability of the model\n",
    "\n",
    "**Answer:** To improve the accuracy of the model\n",
    "\n",
    "**Explanation:** The main objective of Boosting Technique is to combine multiple weak learners (models) to create a strong learner that improves the accuracy of the model by reducing bias and variance errors.\n",
    "\n",
    "---\n",
    "\n",
    "**2. Which algorithm is used in AdaBoost for adjusting the weights of misclassified samples?**\n",
    "\n",
    "- Gradient Descent\n",
    "- Lasso Regression\n",
    "- Ridge Regression\n",
    "- None of the above\n",
    "\n",
    "**Answer:** None of the above\n",
    "\n",
    "**Explanation:** AdaBoost adjusts the weights of misclassified samples using a weighted approach, where misclassified samples are given higher weights to emphasize their importance in subsequent iterations.\n",
    "\n",
    "---\n",
    "\n",
    "**3. Which of the following is NOT a popular boosting algorithm?**\n",
    "\n",
    "- AdaBoost\n",
    "- Random Forest\n",
    "- XGBoost\n",
    "- Gradient Boosting\n",
    "\n",
    "**Answer:** Random Forest\n",
    "\n",
    "**Explanation:** Random Forest is not a boosting algorithm. It is an ensemble technique that combines multiple decision trees to make predictions, but it does not involve iterative boosting of weak learners like AdaBoost, XGBoost, or Gradient Boosting.\n",
    "\n",
    "---\n",
    "\n",
    "**4. What is the key idea behind Gradient Boosting?**\n",
    "\n",
    "- Adjusting the weights of misclassified samples\n",
    "- Regularizing the model to prevent overfitting\n",
    "- Combining the predictions of weak learners in a weighted manner\n",
    "- Using parallel processing for faster model training\n",
    "\n",
    "**Answer:** Combining the predictions of weak learners in a weighted manner\n",
    "\n",
    "**Explanation:** The key idea behind Gradient Boosting is to combine the predictions of weak learners (typically decision trees) in a sequential manner, where each subsequent model corrects the errors of its predecessor, ultimately creating a strong learner.\n",
    "\n",
    "---\n",
    "\n",
    "**5. What does \"Ada\" stand for in AdaBoost?**\n",
    "\n",
    "- Adaptive\n",
    "- Additional\n",
    "- Accurate\n",
    "- Aggregating\n",
    "\n",
    "**Answer:** Adaptive\n",
    "\n",
    "**Explanation:** \"Ada\" in AdaBoost stands for Adaptive, as the algorithm adaptively adjusts the weights of misclassified samples to improve the accuracy of the model in subsequent iterations.\n",
    "\n",
    "---\n",
    "\n",
    "**6. What type of learning does AdaBoost belong to?**\n",
    "\n",
    "- Supervised Learning\n",
    "- Unsupervised Learning\n",
    "- Semi-supervised Learning\n",
    "- Reinforcement Learning\n",
    "\n",
    "**Answer:** Supervised Learning\n",
    "\n",
    "**Explanation:** AdaBoost is a supervised learning algorithm as it uses labeled data to train a model and make predictions on new, unseen data based on the patterns learned from the labeled data.\n",
    "\n",
    "---\n",
    "\n",
    "**7. Which of the following is a weak learner used in AdaBoost?**\n",
    "\n",
    "- Deep Neural Network\n",
    "- Support Vector Machine\n",
    "- Decision Stump\n",
    "- Random Forest\n",
    "\n",
    "**Answer:** Decision Stump\n",
    "\n",
    "**Explanation:** A decision stump is a simple decision tree with only one level, making it a weak learner. AdaBoost combines multiple decision stumps to create a strong learner.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

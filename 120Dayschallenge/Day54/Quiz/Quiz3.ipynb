{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Which of the following is not a hyperparameter in Xgboost?\n",
    "\n",
    "- Number of trees\n",
    "- Learning rate\n",
    "- Max depth\n",
    "- Number of features\n",
    "\n",
    "**Answer:** Number of features\n",
    "\n",
    "**Explanation:** Hyperparameters are parameters that are set before the model is trained and are not learned from the data. In Xgboost, common hyperparameters include the number of trees, learning rate, and max depth, but the number of features is typically not a hyperparameter.\n",
    "\n",
    "2. Which of the following is a common technique to prevent overfitting in Xgboost?\n",
    "\n",
    "- Increasing the learning rate\n",
    "- Increasing the max depth\n",
    "- Reducing the number of trees\n",
    "- Using regularization\n",
    "\n",
    "**Answer:** Using regularization\n",
    "\n",
    "**Explanation:** Regularization techniques, such as L1 and L2 regularization, are commonly used in Xgboost to prevent overfitting by adding a penalty term to the objective function.\n",
    "\n",
    "3. What is the default objective function in Xgboost for binary classification problems?\n",
    "\n",
    "- Binary logistic regression\n",
    "- Binary cross-entropy\n",
    "- Mean squared error\n",
    "- None of the above\n",
    "\n",
    "**Answer:** Binary cross-entropy\n",
    "\n",
    "**Explanation:** Binary cross-entropy is the default objective function in Xgboost for binary classification problems. It measures the difference between the predicted probabilities and the actual class labels.\n",
    "\n",
    "4. Which of the following is a limitation of Xgboost?\n",
    "\n",
    "- It can handle missing data easily\n",
    "- It requires large amounts of training data\n",
    "- It is not scalable to large datasets\n",
    "- It cannot handle categorical features\n",
    "\n",
    "**Answer:** It requires large amounts of training data\n",
    "\n",
    "**Explanation:** While Xgboost is a powerful algorithm, it may require large amounts of training data to achieve good performance, which can be a limitation in some scenarios.\n",
    "\n",
    "5. Which of the following is a parameter in Xgboost that controls the trade-off between overfitting and underfitting?\n",
    "\n",
    "- Learning rate\n",
    "- Max depth\n",
    "- Gamma\n",
    "- Subsample\n",
    "\n",
    "**Answer:** Gamma\n",
    "\n",
    "**Explanation:** Gamma is a regularization parameter in Xgboost that controls the minimum loss reduction required to make a further partition on a leaf node of the tree. It helps to balance the trade-off between overfitting and underfitting.\n",
    "\n",
    "6. Which of the following is a parameter in Xgboost that controls the fraction of observations to be randomly sampled for each tree?\n",
    "\n",
    "- Learning rate\n",
    "- Max depth\n",
    "- Gamma\n",
    "- Subsample\n",
    "\n",
    "**Answer:** Subsample\n",
    "\n",
    "**Explanation:** Subsample is a parameter in Xgboost that controls the fraction of observations to be randomly sampled for each tree. It helps to introduce randomness and reduce overfitting.\n",
    "\n",
    "7. Which of the following is a parameter in Xgboost that controls the weights of positive and negative examples in the loss function?\n",
    "\n",
    "- Scale positive weight\n",
    "- Gamma\n",
    "- Min child weight\n",
    "- Subsample\n",
    "\n",
    "**Answer:** Scale positive weight\n",
    "\n",
    "**Explanation:** Scale positive weight is a parameter in Xgboost that controls the weights of positive and negative examples in the loss function, particularly useful for handling imbalanced datasets in binary classification problems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

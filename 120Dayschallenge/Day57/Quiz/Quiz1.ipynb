{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What is the main difference between supervised and unsupervised learning?\n",
    "\n",
    "   - Supervised learning requires labeled data, while unsupervised learning does not.\n",
    "   - Supervised learning is only suitable for small datasets, while unsupervised learning can handle large datasets.\n",
    "   - Supervised learning always produces more accurate results than unsupervised learning.\n",
    "   - Supervised learning can handle any type of data, while unsupervised learning is limited to numerical data.\n",
    "\n",
    "**Answer:** \n",
    "Supervised learning requires labeled data, while unsupervised learning does not.\n",
    "\n",
    "**Explanation:** \n",
    "Supervised learning involves training a model on labeled data, where each training example is paired with the correct output. In contrast, unsupervised learning deals with unlabeled data, where the algorithm tries to find hidden structure or patterns in the input data without explicit guidance.\n",
    "\n",
    "2. What is the main difference between hierarchical clustering and k-means clustering?\n",
    "\n",
    "   - Hierarchical clustering forms clusters by partitioning the data, while k-means clustering forms them recursively.\n",
    "   - Hierarchical clustering can handle any number of clusters, while k-means clustering requires a predefined number of clusters.\n",
    "   - Hierarchical clustering always produces the same set of clusters, while k-means clustering may produce different sets of clusters depending on the initial conditions.\n",
    "   - Hierarchical clustering is only suitable for small datasets, while k-means clustering can handle large datasets.\n",
    "\n",
    "**Answer:** \n",
    "Hierarchical clustering can handle any number of clusters, while k-means clustering requires a predefined number of clusters.\n",
    "\n",
    "**Explanation:** \n",
    "Hierarchical clustering builds a tree-like structure of nested clusters, allowing for flexibility in the number of clusters. In contrast, k-means clustering partitions the data points into a fixed number of clusters, which must be specified beforehand.\n",
    "\n",
    "3. What is the difference between agglomerative and divisive hierarchical clustering?\n",
    "\n",
    "   - Agglomerative clustering forms clusters by dividing the data, while divisive clustering forms them by combining the data.\n",
    "   - Agglomerative clustering forms clusters by recursively combining the data, while divisive clustering forms clusters by recursively dividing the data.\n",
    "   - Agglomerative clustering always produces the same set of clusters, while divisive clustering may produce different sets of clusters depending on the initial conditions.\n",
    "   - Agglomerative clustering is only suitable for small datasets, while divisive clustering can handle large datasets.\n",
    "\n",
    "**Answer:** \n",
    "Agglomerative clustering forms clusters by recursively combining the data, while divisive clustering forms clusters by recursively dividing the data.\n",
    "\n",
    "**Explanation:** \n",
    "Agglomerative clustering starts with individual data points as separate clusters and merges them based on similarity, while divisive clustering starts with all data points in one cluster and recursively splits them.\n",
    "\n",
    "4. What is the main advantage of k-means clustering compared to hierarchical clustering?\n",
    "\n",
    "   - K-means clustering can handle any number of clusters, while hierarchical clustering requires a predefined number of clusters.\n",
    "   - K-means clustering always produces the same set of clusters, while hierarchical clustering may produce different sets of clusters depending on the initial conditions.\n",
    "   - K-means clustering is faster and more scalable than hierarchical clustering.\n",
    "   - K-means clustering produces more accurate results than hierarchical clustering.\n",
    "\n",
    "**Answer:** \n",
    "K-means clustering is faster and more scalable than hierarchical clustering.\n",
    "\n",
    "**Explanation:** \n",
    "K-means clustering is computationally less expensive and can handle larger datasets compared to hierarchical clustering, making it more suitable for applications with large amounts of data.\n",
    "\n",
    "5. What is the main disadvantage of k-means clustering?\n",
    "\n",
    "   - It is only suitable for small datasets.\n",
    "   - It requires labeled data.\n",
    "   - It is sensitive to the initial choice of cluster centers.\n",
    "   - It can only handle numerical data.\n",
    "\n",
    "**Answer:** \n",
    "It is sensitive to the initial choice of cluster centers.\n",
    "\n",
    "**Explanation:** \n",
    "K-means clustering's performance can vary significantly depending on the initial placement of cluster centroids, making it sensitive to the initial conditions and potentially leading to suboptimal clustering results.\n",
    "\n",
    "6. Which of the following is a type of non-hierarchical clustering?\n",
    "\n",
    "   - K-means clustering\n",
    "   - Agglomerative clustering\n",
    "   - Divisive clustering\n",
    "   - Ward's clustering\n",
    "\n",
    "**Answer:** \n",
    "K-means clustering\n",
    "\n",
    "**Explanation:** \n",
    "K-means clustering is a type of non-hierarchical clustering algorithm that partitions the data points into a fixed number of clusters without forming a hierarchical structure.\n",
    "\n",
    "7. What is the elbow method used for in k-means clustering?\n",
    "\n",
    "   - To determine the optimal number of clusters\n",
    "   - To calculate the distance between clusters\n",
    "   - To determine the size of each cluster\n",
    "   - To determine the centroids of each cluster\n",
    "\n",
    "**Answer:** \n",
    "To determine the optimal number of clusters\n",
    "\n",
    "**Explanation:** \n",
    "The elbow method is a heuristic used to find the optimal number of clusters in k-means clustering by plotting the within-cluster sum of squares (WCSS) against the number of clusters and identifying the \"elbow\" point where the rate of decrease in WCSS slows down.\n",
    "\n",
    "8. Which of the following is an example of a distance metric used in clustering?\n",
    "\n",
    "   - Euclidean distance\n",
    "   - Accuracy score\n",
    "   - Precision\n",
    "   - Recall\n",
    "\n",
    "**Answer:** \n",
    "Euclidean distance\n",
    "\n",
    "**Explanation:** \n",
    "Euclidean distance is a common distance metric used in clustering to measure the distance between two data points in a multi-dimensional space.\n",
    "\n",
    "9. Which of the following is true about agglomerative clustering?\n",
    "\n",
    "   - It always produces the same set of clusters.\n",
    "   - It requires the number of clusters to be predefined.\n",
    "   - It can be used with any type of distance metric.\n",
    "   - It forms clusters by recursively dividing the data.\n",
    "\n",
    "**Answer:** \n",
    "It can be used with any type of distance metric.\n",
    "\n",
    "**Explanation:** \n",
    "Agglomerative clustering can work with various distance metrics, allowing flexibility in how the similarity between data points is measured during the clustering process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Which of the following statements best describes hierarchical clustering?\n",
    "\n",
    "   - It is a method for partitioning data into clusters based on their similarity.\n",
    "   - It is a method for finding the optimal number of clusters in a dataset.\n",
    "   - It is a method for reducing the dimensionality of data.\n",
    "   - It is a method for constructing a tree-like structure of clusters.\n",
    "\n",
    "**Answer:** \n",
    "It is a method for constructing a tree-like structure of clusters.\n",
    "\n",
    "**Explanation:** \n",
    "Hierarchical clustering is a method for constructing a tree-like structure of clusters, where each node in the tree represents a cluster of data points. The tree can be visualised as a dendrogram, where the branches represent the distance between clusters.\n",
    "\n",
    "2. Which of the following is a key difference between agglomerative and divisive hierarchical clustering?\n",
    "\n",
    "   - Agglomerative clustering starts with individual data points and combines them into clusters, while divisive clustering starts with the entire dataset and divides it into smaller clusters.\n",
    "   - Agglomerative clustering is a bottom-up approach, while divisive clustering is a top-down approach.\n",
    "   - Agglomerative clustering always results in a binary tree, while divisive clustering can result in a tree with more than two branches at each node.\n",
    "   - Agglomerative clustering always results in clusters of equal size, while divisive clustering can result in clusters of unequal size.\n",
    "\n",
    "**Answer:** \n",
    "Agglomerative clustering is a bottom-up approach, while divisive clustering is a top-down approach.\n",
    "\n",
    "**Explanation:** \n",
    "Agglomerative clustering starts with individual data points and gradually merges them into clusters, while divisive clustering starts with the entire dataset and recursively divides it into smaller clusters.\n",
    "\n",
    "3. Which of the following methods is commonly used to measure the distance between clusters in hierarchical clustering?\n",
    "\n",
    "   - Euclidean distance\n",
    "   - Manhattan distance\n",
    "   - Mahalanobis distance\n",
    "   - All of the above\n",
    "\n",
    "**Answer:** \n",
    "All of the above\n",
    "\n",
    "**Explanation:** \n",
    "Various distance metrics can be used in hierarchical clustering, including Euclidean distance, Manhattan distance, and Mahalanobis distance, depending on the characteristics of the data.\n",
    "\n",
    "4. In hierarchical clustering, which of the following is true about the linkage criterion?\n",
    "\n",
    "   - It determines how clusters are combined at each step of the algorithm.\n",
    "   - It determines the distance between data points within a cluster.\n",
    "   - It determines the number of clusters in the final clustering.\n",
    "   - It determines the threshold for stopping the algorithm.\n",
    "\n",
    "**Answer:** \n",
    "It determines how clusters are combined at each step of the algorithm.\n",
    "\n",
    "**Explanation:** \n",
    "The linkage criterion determines the distance or similarity between clusters and influences how clusters are merged at each step of the hierarchical clustering algorithm.\n",
    "\n",
    "5. Which of the following linkage criteria tends to produce elongated clusters?\n",
    "\n",
    "   - Single linkage\n",
    "   - Complete linkage\n",
    "   - Average linkage\n",
    "   - Ward's linkage\n",
    "\n",
    "**Answer:** \n",
    "Single linkage\n",
    "\n",
    "**Explanation:** \n",
    "Single linkage tends to produce elongated clusters because it only considers the distance between the closest points in each cluster when deciding how to merge clusters.\n",
    "\n",
    "6. Which of the following linkage criteria tends to produce compact, spherical clusters?\n",
    "\n",
    "   - Single linkage\n",
    "   - Complete linkage\n",
    "   - Average linkage\n",
    "   - Ward's linkage\n",
    "\n",
    "**Answer:** \n",
    "Ward's linkage\n",
    "\n",
    "**Explanation:** \n",
    "Ward's linkage tends to produce compact, spherical clusters because it minimizes the variance within each cluster when deciding how to merge clusters.\n",
    "\n",
    "7. Agglomerative hierarchical clustering, which of the following is true about the merging process?\n",
    "\n",
    "   - In agglomerative hierarchical clustering, the merging process starts with each data point in its own cluster, and at each iteration, the two closest clusters are merged together until all data points belong to a single cluster.\n",
    "   - The merging process in agglomerative hierarchical clustering is a bottom-up approach, where the algorithm starts with the individual data points as separate clusters and then iteratively merges them until a single cluster containing all the points is formed.\n",
    "   - The merging process in agglomerative hierarchical clustering is a top-down approach, where the algorithm starts with a single cluster containing all the data points and then recursively splits it into smaller clusters until each point is in its own cluster.\n",
    "   - In agglomerative hierarchical clustering, the merging process is based on the distance between the centroids of each cluster, and the two clusters with the smallest distance are merged together at each iteration until a single cluster containing all the data points is formed.\n",
    "\n",
    "**Answer:** \n",
    "In agglomerative hierarchical clustering, the merging process starts with each data point in its own cluster, and at each iteration, the two closest clusters are merged together until all data points belong to a single cluster.\n",
    "\n",
    "**Explanation:** \n",
    "Agglomerative hierarchical clustering is a bottom-up clustering method that starts with each data point in its own cluster. At each iteration, the two closest clusters are merged together until all data points belong to a single cluster.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
